"use strict";(globalThis.webpackChunkcoo_llm_docs=globalThis.webpackChunkcoo_llm_docs||[]).push([[718],{2384:e=>{e.exports=JSON.parse('{"label":"getting-started","permalink":"/coo-llm-main/docs/tags/getting-started","allTagsPath":"/coo-llm-main/docs/tags","count":1,"items":[{"id":"Intro/Overview","title":"COO-LLM Overview","description":"COO-LLM is an intelligent reverse proxy and load balancer for Large Language Model (LLM) APIs. It provides a unified, OpenAI-compatible interface to multiple LLM providers while intelligently distributing requests across API keys and providers based on performance, cost, and rate limits.","permalink":"/coo-llm-main/docs/Intro/Overview"}]}')}}]);