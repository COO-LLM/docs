"use strict";(globalThis.webpackChunkcoo_llm_docs=globalThis.webpackChunkcoo_llm_docs||[]).push([[3357],{5203:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>a});const s=JSON.parse('{"id":"Reference/API","title":"API Reference","description":"COO-LLM provides OpenAI-compatible REST APIs for LLM interactions, plus administrative endpoints for management.","source":"@site/content/Reference/API.md","sourceDirName":"Reference","slug":"/Reference/API","permalink":"/docs/docs/Reference/API","draft":false,"unlisted":false,"editUrl":"https://github.com/coo-llm/coo-llm-main/tree/main/docs/content/content/Reference/API.md","tags":[{"inline":true,"label":"developer-guide","permalink":"/docs/docs/tags/developer-guide"},{"inline":true,"label":"api","permalink":"/docs/docs/tags/api"}],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"tags":["developer-guide","api"]}}');var r=i(4848),t=i(8453);const l={sidebar_position:2,tags:["developer-guide","api"]},o="API Reference",d={},a=[{value:"Authentication",id:"authentication",level:2},{value:"Model Resolution",id:"model-resolution",level:2},{value:"Authentication &amp; Authorization Flow",id:"authentication--authorization-flow",level:2},{value:"API Request Flow",id:"api-request-flow",level:2},{value:"OpenAI-Compatible Endpoints",id:"openai-compatible-endpoints",level:2},{value:"POST /api/v1/chat/completions",id:"post-apiv1chatcompletions",level:3},{value:"POST /api/v1/embeddings",id:"post-apiv1embeddings",level:3},{value:"GET /api/v1/models",id:"get-apiv1models",level:3},{value:"Admin API",id:"admin-api",level:2},{value:"Authentication",id:"authentication-1",level:3},{value:"Endpoints",id:"endpoints",level:3},{value:"GET /api/admin/v1/config",id:"get-apiadminv1config",level:4},{value:"POST /api/admin/v1/config",id:"post-apiadminv1config",level:4},{value:"POST /api/admin/v1/config/validate",id:"post-apiadminv1configvalidate",level:4},{value:"GET /api/admin/v1/metrics",id:"get-apiadminv1metrics",level:4},{value:"GET /api/admin/v1/clients",id:"get-apiadminv1clients",level:4},{value:"GET /api/admin/v1/stats",id:"get-apiadminv1stats",level:4},{value:"POST /api/login",id:"post-apilogin",level:4},{value:"Error Responses",id:"error-responses",level:2},{value:"Rate Limiting",id:"rate-limiting",level:2},{value:"Streaming",id:"streaming",level:2},{value:"Examples",id:"examples",level:2},{value:"Python Client",id:"python-client",level:3},{value:"cURL Examples",id:"curl-examples",level:3},{value:"Authentication",id:"authentication-2",level:2},{value:"SDK Compatibility",id:"sdk-compatibility",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"api-reference",children:"API Reference"})}),"\n",(0,r.jsx)(n.p,{children:"COO-LLM provides OpenAI-compatible REST APIs for LLM interactions, plus administrative endpoints for management."}),"\n",(0,r.jsx)(n.h2,{id:"authentication",children:"Authentication"}),"\n",(0,r.jsx)(n.p,{children:"All API requests require authentication via Bearer token:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Authorization: Bearer <api_key>\n"})}),"\n",(0,r.jsx)(n.p,{children:"API keys are configured in the providers section and mapped to specific keys."}),"\n",(0,r.jsx)(n.h2,{id:"model-resolution",children:"Model Resolution"}),"\n",(0,r.jsx)(n.p,{children:"COO-LLM supports 3 ways to specify models:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsxs)(n.strong,{children:["Direct provider",":model"," syntax"]}),": ",(0,r.jsx)(n.code,{children:"provider_id:model_name"})," (e.g., ",(0,r.jsx)(n.code,{children:"openai:gpt-4o"}),", ",(0,r.jsx)(n.code,{children:"custom:my-model"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Model aliases"}),": Short names mapped to provider",":model"," (e.g., ",(0,r.jsx)(n.code,{children:"gpt-4o"})," \u2192 ",(0,r.jsx)(n.code,{children:"openai:gpt-4o"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Pattern matching fallback"}),": Infer provider from model name (e.g., ",(0,r.jsx)(n.code,{children:"gpt-4o"})," \u2192 OpenAI provider)"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"authentication--authorization-flow",children:"Authentication & Authorization Flow"}),"\n",(0,r.jsx)(n.p,{children:"Authentication flow for API requests:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Client sends request with Bearer token"}),"\n",(0,r.jsx)(n.li,{children:"Extract API key from Authorization header"}),"\n",(0,r.jsx)(n.li,{children:"Validate key exists in configuration"}),"\n",(0,r.jsx)(n.li,{children:"Check if provider is allowed for this key"}),"\n",(0,r.jsx)(n.li,{children:"Proceed with request processing or return error"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"api-request-flow",children:"API Request Flow"}),"\n",(0,r.jsx)(n.p,{children:"Request processing pipeline:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Client sends chat completion request"}),"\n",(0,r.jsx)(n.li,{children:"Authentication via Bearer token"}),"\n",(0,r.jsxs)(n.li,{children:["Model alias resolution to provider",":model"]}),"\n",(0,r.jsx)(n.li,{children:"Provider and key selection with load balancing"}),"\n",(0,r.jsx)(n.li,{children:"Rate limit checking"}),"\n",(0,r.jsx)(n.li,{children:"External API call to LLM provider"}),"\n",(0,r.jsx)(n.li,{children:"Response processing with token counting"}),"\n",(0,r.jsx)(n.li,{children:"Usage tracking and metrics update"}),"\n",(0,r.jsx)(n.li,{children:"Return OpenAI-compatible JSON response"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"openai-compatible-endpoints",children:"OpenAI-Compatible Endpoints"}),"\n",(0,r.jsx)(n.h3,{id:"post-apiv1chatcompletions",children:"POST /api/v1/chat/completions"}),"\n",(0,r.jsx)(n.p,{children:"Generate chat completions using available models. This is the primary endpoint implemented in COO-LLM."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Request Body:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "model": "gpt-4o",\n  "messages": [\n    {\n      "role": "user",\n      "content": "Hello, how are you?"\n    }\n  ],\n  "max_tokens": 100\n}\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Response:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "id": "chatcmpl-1234567890",\n  "object": "chat.completion",\n  "created": 1699123456,\n  "model": "gpt-4o",\n  "choices": [\n    {\n      "index": 0,\n      "message": {\n        "role": "assistant",\n        "content": "Hello! I\'m doing well, thank you for asking."\n      },\n      "finish_reason": "stop"\n    }\n  ],\n  "usage": {\n    "prompt_tokens": 13,\n    "completion_tokens": 7,\n    "total_tokens": 20,\n    "cost": 0.000036\n  }\n}\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"model"}),' (string, required): Model alias from configuration (e.g., "gpt-4o", "gemini-1.5-pro")']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"messages"})," (array, required): Chat messages with role/content format"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"max_tokens"})," (integer, optional): Maximum tokens to generate (default: 1000)"]}),"\n",(0,r.jsx)(n.li,{children:"Additional parameters are passed through to the provider"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Features:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\u2705 Conversation history support"}),"\n",(0,r.jsx)(n.li,{children:"\u2705 Model alias resolution"}),"\n",(0,r.jsx)(n.li,{children:"\u2705 Automatic provider selection and load balancing"}),"\n",(0,r.jsx)(n.li,{children:"\u2705 Rate limiting and retry logic"}),"\n",(0,r.jsx)(n.li,{children:"\u2705 Response caching (if enabled)"}),"\n",(0,r.jsx)(n.li,{children:"\u2705 Usage tracking and cost calculation"}),"\n",(0,r.jsx)(n.li,{children:"\u2705 Comprehensive logging"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"post-apiv1embeddings",children:"POST /api/v1/embeddings"}),"\n",(0,r.jsx)(n.p,{children:"Generate embeddings for text inputs."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Request Body:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "model": "text-embedding-3-small",\n  "input": "Hello, world!",\n  "encoding_format": "float",\n  "dimensions": 1536,\n  "user": "user123"\n}\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Response:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "object": "list",\n  "data": [\n    {\n      "object": "embedding",\n      "embedding": [0.1, 0.2, ...],\n      "index": 0\n    }\n  ],\n  "model": "text-embedding-3-small",\n  "usage": {\n    "prompt_tokens": 4,\n    "total_tokens": 4\n  }\n}\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"model"})," (string, required): Embedding model to use"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"input"})," (string/array, required): Text to embed"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"encoding_format"}),' (string, optional): "float" or "base64"']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"dimensions"})," (integer, optional): Output dimensions"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"user"})," (string, optional): User identifier"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"get-apiv1models",children:"GET /api/v1/models"}),"\n",(0,r.jsx)(n.p,{children:"List available models based on configured model aliases."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Response:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "object": "list",\n  "data": [\n    {\n      "id": "gpt-4o",\n      "object": "model",\n      "created": 1699123456,\n      "owned_by": "coo-llm"\n    },\n    {\n      "id": "gemini-1.5-pro",\n      "object": "model",\n      "created": 1699123456,\n      "owned_by": "coo-llm"\n    }\n  ]\n}\n\n**Note:** Models are listed based on `model_aliases` configuration, not actual provider models.\n\n## Admin API Endpoints\n\n**Note:** Admin API endpoints are not yet implemented in the current version. The following are planned for future releases:\n\n### Admin Endpoints\n\n- `GET /api/admin/v1/config` - Get current configuration (from store)\n- `POST /api/admin/v1/config` - Update configuration in store\n- `POST /api/admin/v1/config/validate` - Validate configuration\n- `GET /api/admin/v1/metrics` - Retrieve historical metrics data\n- `GET /api/admin/v1/clients` - Get aggregated statistics per client API key\n- `GET /api/admin/v1/stats` - Get aggregated statistics with flexible grouping\n- `POST /api/login` - Authenticate for Web UI access\n\n### Configuration Management\n\nCOO-LLM supports dynamic configuration management:\n\n- **Startup**: Loads base config from YAML, saves public config to store\n- **Runtime Sync**: Instances share public config from store, secrets from ENV\n- **Updates**: Admin can update config via API, synced across instances\n- **Security**: API keys stored as `\\${ENV_VAR}`, resolved at runtime, never saved to store\n\n## Metrics Endpoint\n\n### GET /api/metrics\n\nPrometheus metrics endpoint (enabled when `logging.prometheus.enabled: true`).\n\n**Response:** Prometheus format metrics\n\n'})}),"\n",(0,r.jsx)(n.h1,{id:"help-llm_requests_total-total-number-of-llm-requests",children:"HELP llm_requests_total Total number of LLM requests"}),"\n",(0,r.jsx)(n.h1,{id:"type-llm_requests_total-counter",children:"TYPE llm_requests_total counter"}),"\n",(0,r.jsx)(n.p,{children:'llm_requests_total{provider="openai",model="gpt-4"} 1250'}),"\n",(0,r.jsx)(n.h1,{id:"help-llm_request_duration_seconds-request-duration-in-seconds",children:"HELP llm_request_duration_seconds Request duration in seconds"}),"\n",(0,r.jsx)(n.h1,{id:"type-llm_request_duration_seconds-histogram",children:"TYPE llm_request_duration_seconds histogram"}),"\n",(0,r.jsx)(n.p,{children:'llm_request_duration_seconds_bucket{provider="openai",le="0.1"} 1200\n...'}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'\n**Available Metrics:**\n- Request counts by provider/model\n- Request duration histograms\n- Error rates\n- Token usage tracking\n- Active connections\n\n**Configuration:**\n```yaml\nlogging:\n  prometheus:\n    enabled: true\n    endpoint: "/metrics"\n'})}),"\n",(0,r.jsx)(n.h2,{id:"admin-api",children:"Admin API"}),"\n",(0,r.jsx)(n.p,{children:"Administrative endpoints for configuration and monitoring (require admin authentication):"}),"\n",(0,r.jsx)(n.h3,{id:"authentication-1",children:"Authentication"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'curl -H "Authorization: Bearer your-admin-key" http://localhost:2906/api/admin/v1/config\n'})}),"\n",(0,r.jsx)(n.h3,{id:"endpoints",children:"Endpoints"}),"\n",(0,r.jsx)(n.h4,{id:"get-apiadminv1config",children:"GET /api/admin/v1/config"}),"\n",(0,r.jsx)(n.p,{children:"Get current configuration from store (sensitive data masked)."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Response:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "version": "1.0",\n  "server": {\n    "listen": ":2906",\n    "admin_api_key": "****"\n  },\n  "llm_providers": [],\n  "api_keys": [\n    {\n      "id": "client-001",\n      "key": "sk-****",\n      "allowed_providers": ["openai"],\n      "description": "Production client"\n    }\n  ]\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"post-apiadminv1config",children:"POST /api/admin/v1/config"}),"\n",(0,r.jsx)(n.p,{children:"Update configuration in store (only public fields)."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Request Body:"})," Config JSON with public fields\n",(0,r.jsx)(n.strong,{children:"Response:"})," ",(0,r.jsx)(n.code,{children:'{"message": "Config updated successfully"}'})]}),"\n",(0,r.jsx)(n.h4,{id:"post-apiadminv1configvalidate",children:"POST /api/admin/v1/config/validate"}),"\n",(0,r.jsx)(n.p,{children:"Validate configuration without applying."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Request Body:"})," Full config JSON\n",(0,r.jsx)(n.strong,{children:"Response:"})," ",(0,r.jsx)(n.code,{children:'{"message": "Config is valid"}'})," or error"]}),"\n",(0,r.jsx)(n.h4,{id:"get-apiadminv1metrics",children:"GET /api/admin/v1/metrics"}),"\n",(0,r.jsx)(n.p,{children:"Retrieve historical metrics data."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Query Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"name"}),": Metric name (",(0,r.jsx)(n.code,{children:"latency"}),", ",(0,r.jsx)(n.code,{children:"tokens"}),", ",(0,r.jsx)(n.code,{children:"cost"}),") - default: ",(0,r.jsx)(n.code,{children:"latency"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"start"}),": Start timestamp (Unix seconds) - default: 1 hour ago"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"end"}),": End timestamp (Unix seconds) - default: now"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Response:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "name": "latency",\n  "start": 1700000000,\n  "end": 1700003600,\n  "points": [\n    {\n      "value": 150.5,\n      "timestamp": 1700000100\n    }\n  ]\n}\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Metrics Tags:"})," ",(0,r.jsx)(n.code,{children:"provider"}),", ",(0,r.jsx)(n.code,{children:"key"}),", ",(0,r.jsx)(n.code,{children:"model"}),", ",(0,r.jsx)(n.code,{children:"client_key"})]}),"\n",(0,r.jsx)(n.h4,{id:"get-apiadminv1clients",children:"GET /api/admin/v1/clients"}),"\n",(0,r.jsx)(n.p,{children:"Get aggregated statistics per client API key."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Query Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"start"}),": Start timestamp (Unix seconds) - default: 24 hours ago"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"end"}),": End timestamp (Unix seconds) - default: now"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Response:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "start": 1700000000,\n  "end": 1700003600,\n  "client_stats": {\n    "test-12": {\n      "queries": 150,\n      "tokens": 25000,\n      "cost": 0.125\n    },\n    "gemini-only": {\n      "queries": 75,\n      "tokens": 15000,\n      "cost": 0.075\n    }\n  }\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"get-apiadminv1stats",children:"GET /api/admin/v1/stats"}),"\n",(0,r.jsx)(n.p,{children:"Get aggregated statistics with flexible grouping and filtering."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Query Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"group_by"}),": Comma-separated list of dimensions to group by (e.g., ",(0,r.jsx)(n.code,{children:"client_key,provider"}),") - default: ",(0,r.jsx)(n.code,{children:"client_key"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"start"}),": Start timestamp (Unix seconds) - default: 24 hours ago"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"end"}),": End timestamp (Unix seconds) - default: now"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"client_key"}),": Filter by specific client key"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"provider"}),": Filter by specific provider"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"key"}),": Filter by specific provider key"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Supported group_by dimensions:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"client_key"}),": Group by client API key"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"provider"}),": Group by provider ID"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"key"}),": Group by provider key ID"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"model"}),": Group by model name"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Response:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "start": 1700000000,\n  "end": 1700003600,\n  "group_by": ["client_key", "provider"],\n  "filters": {"client_key": "test-12"},\n  "stats": {\n    "test-12": {\n      "openai": {\n        "queries": 100,\n        "tokens": 15000,\n        "cost": 0.075\n      },\n      "gemini": {\n        "queries": 50,\n        "tokens": 10000,\n        "cost": 0.050\n      }\n    }\n  }\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"post-apilogin",children:"POST /api/login"}),"\n",(0,r.jsx)(n.p,{children:"Authenticate for Web UI access."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Request:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "admin_id": "admin",\n  "password": "password"\n}\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Response:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "token": "webui-admin-1700000000"\n}\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Note:"})," Login endpoint is at ",(0,r.jsx)(n.code,{children:"/api/login"})," for Web UI authentication."]}),"\n",(0,r.jsx)(n.h2,{id:"error-responses",children:"Error Responses"}),"\n",(0,r.jsx)(n.p,{children:"All endpoints return standard HTTP status codes:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"200"}),": Success"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"400"}),": Bad Request (invalid parameters)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"401"}),": Unauthorized (invalid API key)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"403"}),": Forbidden (rate limited or quota exceeded)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"404"}),": Not Found (invalid endpoint or model)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"429"}),": Too Many Requests (rate limited)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"500"}),": Internal Server Error"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"502"}),": Bad Gateway (provider error)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"503"}),": Service Unavailable (provider down)"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Error response format:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "error": {\n    "message": "Invalid model specified",\n    "type": "invalid_request_error",\n    "code": 400\n  }\n}\n'})}),"\n",(0,r.jsx)(n.h2,{id:"rate-limiting",children:"Rate Limiting"}),"\n",(0,r.jsx)(n.p,{children:"COO-LLM implements rate limiting based on configured limits:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Per-key request limits"}),"\n",(0,r.jsx)(n.li,{children:"Per-key token limits"}),"\n",(0,r.jsx)(n.li,{children:"Global rate limits"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Rate limited requests return ",(0,r.jsx)(n.code,{children:"429"})," status with retry information."]}),"\n",(0,r.jsx)(n.h2,{id:"streaming",children:"Streaming"}),"\n",(0,r.jsx)(n.p,{children:"Streaming responses are supported for chat completions:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'curl -X POST http://localhost:2906/api/v1/chat/completions \\\n  -H "Authorization: Bearer your-key" \\\n  -d \'{"model": "gpt-4", "messages": [{"role": "user", "content": "Tell me a story"}], "stream": true}\'\n'})}),"\n",(0,r.jsx)(n.p,{children:"Response is Server-Sent Events format."}),"\n",(0,r.jsx)(n.h2,{id:"examples",children:"Examples"}),"\n",(0,r.jsx)(n.h3,{id:"python-client",children:"Python Client"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import openai\n\n# Point to COO-LLM instead of OpenAI\nclient = openai.OpenAI(\n    api_key="dummy-key",  # COO-LLM ignores this, uses config-based auth\n    base_url="http://localhost:2906/api/v1"\n)\n\nresponse = client.chat.completions.create(\n    model="gpt-4o",\n    messages=[{"role": "user", "content": "Hello!"}]\n)\n\nprint(response.choices[0].message.content)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"curl-examples",children:"cURL Examples"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Chat completion with API key auth\ncurl -X POST http://localhost:2906/api/v1/chat/completions \\\n  -H "Authorization: Bearer test-key" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "model": "gpt-4o",\n    "messages": [{"role": "user", "content": "Hello"}]\n  }\'\n\n# List available models\ncurl http://localhost:2906/api/v1/models \\\n  -H "Authorization: Bearer test-key"\n\n# Prometheus metrics\ncurl http://localhost:2906/metrics\n'})}),"\n",(0,r.jsx)(n.h2,{id:"authentication-2",children:"Authentication"}),"\n",(0,r.jsxs)(n.p,{children:["COO-LLM uses API key authentication via the ",(0,r.jsx)(n.code,{children:"Authorization: Bearer <key>"})," header. API keys are configured in the ",(0,r.jsx)(n.code,{children:"api_keys"})," section and map to allowed providers."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'api_keys:\n  - key: "client-a-key"\n    allowed_providers: ["openai-prod"]  # Limited access\n  - key: "premium-key"\n    allowed_providers: ["*"]  # Full access\n'})}),"\n",(0,r.jsx)(n.h2,{id:"sdk-compatibility",children:"SDK Compatibility"}),"\n",(0,r.jsx)(n.p,{children:"COO-LLM is compatible with:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["OpenAI Python SDK (",(0,r.jsx)(n.code,{children:"openai>=1.0"}),")"]}),"\n",(0,r.jsx)(n.li,{children:"OpenAI Node.js SDK"}),"\n",(0,r.jsx)(n.li,{children:"Any HTTP client following OpenAI Chat Completions API format"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Simply change the ",(0,r.jsx)(n.code,{children:"base_url"})," to point to your COO-LLM instance and use any API key from your configuration."]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>o});var s=i(6540);const r={},t=s.createContext(r);function l(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);