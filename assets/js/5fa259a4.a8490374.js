"use strict";(globalThis.webpackChunkcoo_llm_docs=globalThis.webpackChunkcoo_llm_docs||[]).push([[9998],{8453:(e,n,r)=>{r.d(n,{R:()=>t,x:()=>l});var o=r(6540);const i={},s=o.createContext(i);function t(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),o.createElement(s.Provider,{value:n},e.children)}},9308:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>p,frontMatter:()=>t,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"Developer-Guide/Providers/Fireworks","title":"Fireworks AI Provider","description":"---","source":"@site/content/Developer-Guide/Providers/Fireworks.md","sourceDirName":"Developer-Guide/Providers","slug":"/Developer-Guide/Providers/Fireworks","permalink":"/docs/docs/Developer-Guide/Providers/Fireworks","draft":false,"unlisted":false,"editUrl":"https://github.com/coo-llm/coo-llm-main/tree/main/docs/content/content/Developer-Guide/Providers/Fireworks.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Voyage AI Provider","permalink":"/docs/docs/Developer-Guide/Providers/Voyage"},"next":{"title":"Admin API Reference","permalink":"/docs/docs/Reference/Admin-API"}}');var i=r(4848),s=r(8453);const t={},l="Fireworks AI Provider",a={},d=[{value:"sidebar_position: 2\ntags: [developer-guide, providers, fireworks]",id:"sidebar_position-2tags-developer-guide-providers-fireworks",level:2},{value:"Configuration",id:"configuration",level:2},{value:"API Key Setup",id:"api-key-setup",level:2},{value:"Getting API Keys",id:"getting-api-keys",level:2},{value:"Notes",id:"notes",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"fireworks-ai-provider",children:"Fireworks AI Provider"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"sidebar_position-2tags-developer-guide-providers-fireworks",children:"sidebar_position: 2\ntags: [developer-guide, providers, fireworks]"}),"\n",(0,i.jsx)(n.h1,{id:"fireworks-ai-provider-1",children:"Fireworks AI Provider"}),"\n",(0,i.jsx)(n.p,{children:"Fireworks AI provides fast inference for open-source large language models, offering OpenAI-compatible APIs for seamless integration."}),"\n",(0,i.jsx)(n.h2,{id:"configuration",children:"Configuration"}),"\n",(0,i.jsxs)(n.p,{children:["Add to your ",(0,i.jsx)(n.code,{children:"llm_providers"})," array in ",(0,i.jsx)(n.code,{children:"config.yaml"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'llm_providers:\n  - id: "fireworks"  # Provider ID for routing\n    type: "fireworks"\n    api_keys: ["${FIREWORKS_KEY}"]  # ENV var resolved at runtime\n    base_url: "https://api.fireworks.ai/inference/v1"  # Optional\n    model: "accounts/fireworks/models/llama-v3-70b-instruct"  # Default model\n    pricing:\n      input_token_cost: 0.0000009  # $0.90 per million tokens\n      output_token_cost: 0.0000009  # $0.90 per million tokens\n    limits:\n      req_per_min: 100\n      tokens_per_min: 100000\n      max_tokens: 4096\n      session_limit: 10000000\n      session_type: "1d"\n'})}),"\n",(0,i.jsx)(n.h2,{id:"api-key-setup",children:"API Key Setup"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Go to ",(0,i.jsx)(n.a,{href:"https://app.fireworks.ai/",children:"Fireworks AI Console"})]}),"\n",(0,i.jsx)(n.li,{children:"Create a new API key"}),"\n",(0,i.jsxs)(n.li,{children:["Set as environment variable: ",(0,i.jsx)(n.code,{children:'export FIREWORKS_KEY="your-key-here"'})]}),"\n",(0,i.jsxs)(n.li,{children:["Use ",(0,i.jsx)(n.code,{children:"${FIREWORKS_KEY}"})," in config for runtime resolution\nlimits:\nreq_per_min: 60\ntokens_per_min: 60000"]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'\n## Supported Models\n\n### Chat Completion Models\n- `accounts/fireworks/models/llama-v3-8b-instruct` - Llama 3 8B Instruct\n- `accounts/fireworks/models/llama-v3-70b-instruct` - Llama 3 70B Instruct\n- `accounts/fireworks/models/mixtral-8x7b-instruct` - Mixtral 8x7B Instruct\n- `accounts/fireworks/models/qwen2-72b-instruct` - Qwen2 72B Instruct\n- `accounts/fireworks/models/yi-large` - Yi Large\n- `accounts/fireworks/models/gemma-7b-it` - Gemma 7B IT\n- `accounts/fireworks/models/llama-v2-7b-chat` - Llama 2 7B Chat\n- `accounts/fireworks/models/llama-v2-13b-chat` - Llama 2 13B Chat\n- `accounts/fireworks/models/llama-v2-70b-chat` - Llama 2 70B Chat\n\n### Embedding Models\nFireworks supports embeddings through their OpenAI-compatible API. Common embedding models include:\n- `nomic-ai/nomic-embed-text-v1.5`\n- `thenlper/gte-large`\n\n## API Compatibility\n\n- \u2705 Chat Completions (`/v1/chat/completions`)\n- \u2705 Streaming responses\n- \u2705 Embeddings (`/v1/embeddings`)\n- \u2705 Model listing\n- \u2705 Function calling (where supported by underlying models)\n\n## Features\n\n- **High Performance**: Optimized inference for low latency\n- **Open-Source Focus**: Access to popular open-source models\n- **OpenAI Compatibility**: Drop-in replacement for OpenAI API\n- **Cost Effective**: Competitive pricing for high-volume usage\n\n## Rate Limits\n\nDefault limits (configurable):\n- 60 requests per minute\n- 60,000 tokens per minute\n\n## Usage Examples\n\n```bash\n# Chat completion\ncurl -X POST http://localhost:8080/v1/chat/completions \\\n  -H "Authorization: Bearer your-key" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "model": "fireworks:accounts/fireworks/models/llama-v3-8b-instruct",\n    "messages": [{"role": "user", "content": "Hello!"}]\n  }\'\n\n# Embeddings\ncurl -X POST http://localhost:8080/v1/embeddings \\\n  -H "Authorization: Bearer your-key" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "model": "fireworks:nomic-ai/nomic-embed-text-v1.5",\n    "input": ["Hello world"]\n  }\'\n'})}),"\n",(0,i.jsx)(n.h2,{id:"getting-api-keys",children:"Getting API Keys"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Sign up at ",(0,i.jsx)(n.a,{href:"https://fireworks.ai/",children:"Fireworks AI"})]}),"\n",(0,i.jsx)(n.li,{children:"Generate an API key from your dashboard"}),"\n",(0,i.jsx)(n.li,{children:"Add the key to your COO-LLM configuration"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"notes",children:"Notes"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Fireworks AI specializes in fast inference for open-source models"}),"\n",(0,i.jsxs)(n.li,{children:["Model names follow the ",(0,i.jsx)(n.code,{children:"accounts/fireworks/models/{model-name}"})," format"]}),"\n",(0,i.jsx)(n.li,{children:"Pricing is typically lower than proprietary model providers"}),"\n",(0,i.jsx)(n.li,{children:"Excellent choice for cost-conscious deployments requiring high throughput"}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}}}]);