"use strict";(globalThis.webpackChunkcoo_llm_docs=globalThis.webpackChunkcoo_llm_docs||[]).push([[5643],{1286:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"Reference/LLM-API","title":"LLM API Reference","description":"OpenAI-compatible REST APIs for LLM interactions.","source":"@site/content/Reference/LLM-API.md","sourceDirName":"Reference","slug":"/Reference/LLM-API","permalink":"/docs/docs/Reference/LLM-API","draft":false,"unlisted":false,"editUrl":"https://github.com/coo-llm/coo-llm-main/tree/main/docs/content/content/Reference/LLM-API.md","tags":[{"inline":true,"label":"reference","permalink":"/docs/docs/tags/reference"},{"inline":true,"label":"api","permalink":"/docs/docs/tags/api"},{"inline":true,"label":"llm","permalink":"/docs/docs/tags/llm"}],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"tags":["reference","api","llm"]},"sidebar":"tutorialSidebar","previous":{"title":"Admin API Reference","permalink":"/docs/docs/Reference/Admin-API"},"next":{"title":"Load Balancer","permalink":"/docs/docs/Reference/Balancer"}}');var t=r(4848),i=r(8453);const o={sidebar_position:1,tags:["reference","api","llm"]},l="LLM API Reference",d={},c=[{value:"Authentication",id:"authentication",level:2},{value:"Model Resolution",id:"model-resolution",level:2},{value:"Authentication &amp; Authorization Flow",id:"authentication--authorization-flow",level:2},{value:"API Request Flow",id:"api-request-flow",level:2},{value:"OpenAI-Compatible Endpoints",id:"openai-compatible-endpoints",level:2},{value:"POST /v1/chat/completions",id:"post-v1chatcompletions",level:3},{value:"Streaming Response",id:"streaming-response",level:3},{value:"Error Responses",id:"error-responses",level:3},{value:"Supported Models",id:"supported-models",level:2}];function a(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"llm-api-reference",children:"LLM API Reference"})}),"\n",(0,t.jsx)(n.p,{children:"OpenAI-compatible REST APIs for LLM interactions."}),"\n",(0,t.jsx)(n.h2,{id:"authentication",children:"Authentication"}),"\n",(0,t.jsx)(n.p,{children:"All API requests require authentication via Bearer token:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Authorization: Bearer <api_key>\n"})}),"\n",(0,t.jsxs)(n.p,{children:["API keys are configured in the ",(0,t.jsx)(n.code,{children:"api_keys"})," section and mapped to specific providers."]}),"\n",(0,t.jsx)(n.h2,{id:"model-resolution",children:"Model Resolution"}),"\n",(0,t.jsx)(n.p,{children:"COO-LLM supports 3 ways to specify models:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsxs)(n.strong,{children:["Direct provider",":model"," syntax"]}),": ",(0,t.jsx)(n.code,{children:"provider_id:model_name"})," (e.g., ",(0,t.jsx)(n.code,{children:"openai:gpt-4o"}),", ",(0,t.jsx)(n.code,{children:"custom:my-model"}),")"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Model aliases"}),": Short names mapped to provider",":model"," (e.g., ",(0,t.jsx)(n.code,{children:"gpt-4o"})," \u2192 ",(0,t.jsx)(n.code,{children:"openai:gpt-4o"}),")"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Pattern matching fallback"}),": Infer provider from model name (e.g., ",(0,t.jsx)(n.code,{children:"gpt-4o"})," \u2192 OpenAI provider)"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"authentication--authorization-flow",children:"Authentication & Authorization Flow"}),"\n",(0,t.jsx)(n.mermaid,{value:"flowchart TD\n    classDef client fill:#28a745,color:#fff,stroke:#fff,stroke-width:2px\n    classDef auth fill:#ffc107,color:#000,stroke:#000,stroke-width:2px\n    classDef process fill:#dc3545,color:#fff,stroke:#fff,stroke-width:2px\n    classDef deny fill:#dc3545,color:#fff,stroke:#fff,stroke-width:2px\n\n    A[Client Request<br/>with Bearer token]:::client\n    A --\x3e B[Extract API Key<br/>from Authorization header]:::auth\n    B --\x3e C{Key exists in<br/>api_keys config?}:::auth\n\n    C --\x3e|No| D[401 Unauthorized<br/>Invalid API key]:::deny\n    C --\x3e|Yes| E[Get allowed_providers<br/>for this key]:::auth\n    E --\x3e F{Provider allowed<br/>for this request?}:::auth\n\n    F --\x3e|No| G[403 Forbidden<br/>Access denied to provider]:::deny\n    F --\x3e|Yes| H[Proceed to<br/>Request Processing]:::process"}),"\n",(0,t.jsx)(n.h2,{id:"api-request-flow",children:"API Request Flow"}),"\n",(0,t.jsx)(n.mermaid,{value:"flowchart TD\n    classDef client fill:#28a745,color:#fff,stroke:#fff,stroke-width:2px\n    classDef process fill:#dc3545,color:#fff,stroke:#fff,stroke-width:2px\n    classDef external fill:#007bff,color:#fff,stroke:#fff,stroke-width:2px\n\n    A[Client Request<br/>POST /v1/chat/completions]:::client\n    A --\x3e B[Authentication<br/>Bearer Token Validation]:::process\n    B --\x3e C[Model Alias Resolution<br/>Map to provider:model]:::process\n    C --\x3e D[Provider & Key Selection<br/>Load Balancing Algorithm]:::process\n    D --\x3e E[Rate Limit Check<br/>Per-key limits]:::process\n    E --\x3e F[External API Call<br/>OpenAI/Gemini/Claude]:::external\n    F --\x3e G[Response Processing<br/>Token counting, caching]:::process\n    G --\x3e H[Usage Tracking<br/>Metrics update]:::process\n    H --\x3e I[Return OpenAI-compatible<br/>JSON Response]:::client\n\n    B --\x3e J[401 Unauthorized]:::process\n    E --\x3e K[429 Rate Limited]:::process\n    F --\x3e L[Retry Logic<br/>Up to max_attempts]:::process\n    L --\x3e F\n    L --\x3e M[502/503 Error<br/>Provider failure]:::process"}),"\n",(0,t.jsx)(n.h2,{id:"openai-compatible-endpoints",children:"OpenAI-Compatible Endpoints"}),"\n",(0,t.jsx)(n.h3,{id:"post-v1chatcompletions",children:"POST /v1/chat/completions"}),"\n",(0,t.jsx)(n.p,{children:"Generate chat completions using available models. This is the primary endpoint implemented in COO-LLM."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Request Body:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "model": "gpt-4o",\n  "messages": [\n    {\n      "role": "user",\n      "content": "Hello, how are you?"\n    }\n  ],\n  "max_tokens": 100\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Response:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "id": "chatcmpl-1234567890",\n  "object": "chat.completion",\n  "created": 1699123456,\n  "model": "gpt-4o",\n  "choices": [\n    {\n      "index": 0,\n      "message": {\n        "role": "assistant",\n        "content": "Hello! I\'m doing well, thank you for asking. How can I help you today?"\n      },\n      "finish_reason": "stop"\n    }\n  ],\n  "usage": {\n    "prompt_tokens": 13,\n    "completion_tokens": 17,\n    "total_tokens": 30\n  }\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Parameter"}),(0,t.jsx)(n.th,{children:"Type"}),(0,t.jsx)(n.th,{children:"Required"}),(0,t.jsx)(n.th,{children:"Default"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"model"})}),(0,t.jsx)(n.td,{children:"string"}),(0,t.jsx)(n.td,{children:"Yes"}),(0,t.jsx)(n.td,{children:"-"}),(0,t.jsxs)(n.td,{children:["Model identifier (provider",":model"," or alias)"]})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"messages"})}),(0,t.jsx)(n.td,{children:"array"}),(0,t.jsx)(n.td,{children:"Yes"}),(0,t.jsx)(n.td,{children:"-"}),(0,t.jsx)(n.td,{children:"Array of message objects"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"max_tokens"})}),(0,t.jsx)(n.td,{children:"int"}),(0,t.jsx)(n.td,{children:"No"}),(0,t.jsx)(n.td,{children:"Provider default"}),(0,t.jsx)(n.td,{children:"Maximum tokens to generate"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"temperature"})}),(0,t.jsx)(n.td,{children:"float"}),(0,t.jsx)(n.td,{children:"No"}),(0,t.jsx)(n.td,{children:"1.0"}),(0,t.jsx)(n.td,{children:"Sampling temperature (0.0-2.0)"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"top_p"})}),(0,t.jsx)(n.td,{children:"float"}),(0,t.jsx)(n.td,{children:"No"}),(0,t.jsx)(n.td,{children:"1.0"}),(0,t.jsx)(n.td,{children:"Nucleus sampling (0.0-1.0)"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"stream"})}),(0,t.jsx)(n.td,{children:"bool"}),(0,t.jsx)(n.td,{children:"No"}),(0,t.jsx)(n.td,{children:"false"}),(0,t.jsx)(n.td,{children:"Enable streaming response"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"stop"})}),(0,t.jsx)(n.td,{children:"string/array"}),(0,t.jsx)(n.td,{children:"No"}),(0,t.jsx)(n.td,{children:"-"}),(0,t.jsx)(n.td,{children:"Stop sequences"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"presence_penalty"})}),(0,t.jsx)(n.td,{children:"float"}),(0,t.jsx)(n.td,{children:"No"}),(0,t.jsx)(n.td,{children:"0.0"}),(0,t.jsx)(n.td,{children:"Presence penalty (-2.0-2.0)"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"frequency_penalty"})}),(0,t.jsx)(n.td,{children:"float"}),(0,t.jsx)(n.td,{children:"No"}),(0,t.jsx)(n.td,{children:"0.0"}),(0,t.jsx)(n.td,{children:"Frequency penalty (-2.0-2.0)"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"user"})}),(0,t.jsx)(n.td,{children:"string"}),(0,t.jsx)(n.td,{children:"No"}),(0,t.jsx)(n.td,{children:"-"}),(0,t.jsx)(n.td,{children:"A unique identifier representing your end-user."})]})]})]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Note:"})," Other OpenAI-compatible parameters (e.g., ",(0,t.jsx)(n.code,{children:"temperature"}),", ",(0,t.jsx)(n.code,{children:"top_p"}),", ",(0,t.jsx)(n.code,{children:"stop"}),", ",(0,t.jsx)(n.code,{children:"presence_penalty"}),", ",(0,t.jsx)(n.code,{children:"frequency_penalty"}),") are passed through to the underlying provider."]}),"\n",(0,t.jsx)(n.h3,{id:"streaming-response",children:"Streaming Response"}),"\n",(0,t.jsxs)(n.p,{children:["When ",(0,t.jsx)(n.code,{children:"stream: true"}),", responses are sent as Server-Sent Events:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'data: {"id": "chatcmpl-123", "object": "chat.completion.chunk", "choices": [{"delta": {"content": "Hello"}}]}\n\ndata: {"id": "chatcmpl-123", "object": "chat.completion.chunk", "choices": [{"delta": {"content": "!"}}]}\n\ndata: [DONE]\n'})}),"\n",(0,t.jsx)(n.h3,{id:"error-responses",children:"Error Responses"}),"\n",(0,t.jsx)(n.p,{children:"All errors follow OpenAI format:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "error": {\n    "message": "Invalid API key",\n    "type": "authentication_error",\n    "code": 401\n  }\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"supported-models",children:"Supported Models"}),"\n",(0,t.jsx)(n.p,{children:"COO-LLM supports models from all configured providers:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"OpenAI"}),": gpt-4o, gpt-4-turbo, gpt-3.5-turbo, etc."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Gemini"}),": gemini-1.5-pro, gemini-2.0-flash, etc."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Claude"}),": claude-3-opus, claude-3-sonnet, etc."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Custom"}),": Any provider with custom adapter"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Use ",(0,t.jsx)(n.code,{children:"provider:model"})," syntax for explicit selection."]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(a,{...e})}):a(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>l});var s=r(6540);const t={},i=s.createContext(t);function o(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);