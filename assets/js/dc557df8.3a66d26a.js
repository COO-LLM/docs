"use strict";(globalThis.webpackChunkcoo_llm_docs=globalThis.webpackChunkcoo_llm_docs||[]).push([[8257],{5133:e=>{e.exports=JSON.parse('{"tag":{"label":"developer-guide","permalink":"/docs/docs/tags/developer-guide","allTagsPath":"/docs/docs/tags","count":7,"items":[{"id":"Reference/API","title":"API Reference","description":"COO-LLM provides OpenAI-compatible REST APIs for LLM interactions, plus administrative endpoints for management.","permalink":"/docs/docs/Reference/API"},{"id":"Intro/Architecture","title":"Architecture","description":"This document describes the high-level architecture of COO-LLM, including component interactions and design decisions.","permalink":"/docs/docs/Intro/Architecture"},{"id":"Contributing/Changelog","title":"Changelog","description":"All notable changes to COO-LLM will be documented in this file.","permalink":"/docs/docs/Contributing/Changelog"},{"id":"Contributing/Guidelines","title":"Contributing","description":"Thank you for your interest in contributing to COO-LLM! This document provides guidelines and information for contributors.","permalink":"/docs/docs/Contributing/Guidelines"},{"id":"Reference/Balancer","title":"Load Balancer","description":"The load balancer is the core intelligence of COO-LLM, responsible for selecting optimal provider and API key combinations based on performance, cost, and availability.","permalink":"/docs/docs/Reference/Balancer"},{"id":"Reference/Logging","title":"Logging","description":"COO-LLM provides structured logging with file output and Prometheus metrics integration.","permalink":"/docs/docs/Reference/Logging"},{"id":"Reference/Storage","title":"Storage","description":"COO-LLM uses pluggable storage backends for runtime metrics and caching. The system supports Redis, in-memory, HTTP API, file-based, SQL databases, MongoDB, and DynamoDB storage.","permalink":"/docs/docs/Reference/Storage"}],"unlisted":false}}')}}]);