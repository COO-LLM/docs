"use strict";(globalThis.webpackChunkcoo_llm_docs=globalThis.webpackChunkcoo_llm_docs||[]).push([[7795],{8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>l});var t=i(6540);const r={},s=t.createContext(r);function o(e){const n=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(s.Provider,{value:n},e.children)}},9536:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>a});const t=JSON.parse('{"type":"mdx","permalink":"/docs/","source":"@site/src/pages/index.md","title":"COO-LLM Documentation","description":"\ud83d\ude80 Intelligent Load Balancer for LLM APIs with Full OpenAI Compatibility","frontMatter":{},"unlisted":false}');var r=i(4848),s=i(8453);const o={},l="COO-LLM Documentation",c={},a=[{value:"\ud83d\ude80 Features",id:"-features",level:2},{value:"\u2728 Core Capabilities",id:"-core-capabilities",level:3},{value:"\ud83d\udcb0 Cost &amp; Performance Optimization",id:"-cost--performance-optimization",level:3},{value:"\ud83c\udfe2 Enterprise-Ready",id:"-enterprise-ready",level:3},{value:"\ud83c\udfc1 Quick Start",id:"-quick-start",level:2},{value:"Local Development",id:"local-development",level:3},{value:"Docker",id:"docker",level:3},{value:"\ud83d\udcda Documentation",id:"-documentation",level:2},{value:"Quick Links",id:"quick-links",level:3},{value:"Documentation Structure",id:"documentation-structure",level:3},{value:"\ud83c\udfd7\ufe0f Architecture",id:"\ufe0f-architecture",level:2},{value:"\ud83d\udcca Key Metrics",id:"-key-metrics",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"coo-llm-documentation",children:"COO-LLM Documentation"})}),"\n",(0,r.jsxs)(n.p,{children:["\ud83d\ude80 ",(0,r.jsx)(n.strong,{children:"Intelligent Load Balancer for LLM APIs with Full OpenAI Compatibility"})]}),"\n",(0,r.jsx)(n.p,{children:"COO-LLM is a high-performance reverse proxy that intelligently distributes requests across multiple LLM providers (OpenAI, Google Gemini, Anthropic Claude) and API keys. It provides seamless OpenAI API compatibility, advanced load balancing algorithms, real-time cost optimization, and enterprise-grade observability."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"https://golang.org",children:(0,r.jsx)(n.img,{src:"https://img.shields.io/badge/go-1.21+-blue.svg",alt:"Go Version"})}),"\n",(0,r.jsx)(n.a,{href:"https://docker.com",children:(0,r.jsx)(n.img,{src:"https://img.shields.io/badge/docker-ready-blue.svg",alt:"Docker"})}),"\n",(0,r.jsx)(n.a,{href:"https://devs-in-black.web.app/#license",children:(0,r.jsx)(n.img,{src:"https://img.shields.io/badge/License-DIB-black.svg",alt:"License: DIB"})}),"\n",(0,r.jsx)(n.a,{href:"https://platform.openai.com/docs",children:(0,r.jsx)(n.img,{src:"https://img.shields.io/badge/OpenAI-Compatible-green.svg",alt:"OpenAI Compatible"})})]}),"\n",(0,r.jsx)("a",{href:"https://www.producthunt.com/products/themesforaustralia?embed=true&utm_source=badge-featured&utm_medium=badge&utm_source=badge-coo-llm",target:"_blank",children:(0,r.jsx)("img",{src:"https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=1026670&theme=light&t=1760638369012",alt:"COO-LLM - COO for Our Large Language Model Providers | Product Hunt",width:"250",height:"54"})}),"\n",(0,r.jsx)(n.h2,{id:"-features",children:"\ud83d\ude80 Features"}),"\n",(0,r.jsx)(n.h3,{id:"-core-capabilities",children:"\u2728 Core Capabilities"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\ud83d\udd04 Full OpenAI API Compatibility"}),": Drop-in replacement with identical request/response formats"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\ud83c\udf10 Multi-Provider Support"}),": OpenAI, Google Gemini, Anthropic Claude, and custom providers"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\ud83e\udde0 Intelligent Load Balancing"}),": Advanced algorithms (Round Robin, Least Loaded, Hybrid) with real-time optimization"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\ud83d\udcac Conversation History"}),": Full support for multi-turn conversations and message history"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"-cost--performance-optimization",children:"\ud83d\udcb0 Cost & Performance Optimization"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\ud83d\udcca Real-time Cost Tracking"}),": Monitor and optimize API costs across all providers"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u26a1 Rate Limit Management"}),": Sliding window rate limiting with automatic key rotation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\ud83d\udcc8 Performance Monitoring"}),": Track latency, success rates, token usage, and error patterns"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\ud83d\udd04 Response Caching"}),": Configurable caching to reduce costs and improve performance"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"-enterprise-ready",children:"\ud83c\udfe2 Enterprise-Ready"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\ud83d\udd0c Extensible Architecture"}),": Plugin system for custom providers, storage backends, and logging"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\ud83d\udcca Production Observability"}),": Prometheus metrics, structured logging, and health checks"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u2699\ufe0f Configuration Management"}),": YAML-based configuration with environment variable support"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\ud83d\udd12 Security"}),": API key masking, secure storage, and authentication controls"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"-quick-start",children:"\ud83c\udfc1 Quick Start"}),"\n",(0,r.jsx)(n.h3,{id:"local-development",children:"Local Development"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Clone and build\ngit clone https://github.com/coo-llm/coo-llm-main.git\ncd coo-llm\ngo build -o bin/coo-llm ./cmd/coo-llm\n\n# Configure with environment variables\nexport OPENAI_API_KEY="sk-your-key"\nexport GEMINI_API_KEY="your-gemini-key"\n\n# Run\n./bin/coo-llm\n\n# Test simple request\ncurl -X POST http://localhost:2906/v1/chat/completions \\\n  -H "Content-Type: application/json" \\\n  -d \'{"model": "gpt-4o", "messages": [{"role": "user", "content": "Hello!"}]}\'\n'})}),"\n",(0,r.jsx)(n.h3,{id:"docker",children:"Docker"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Run with local build\ndocker run -p 2906:2906 \\\n  -e OPENAI_API_KEY="sk-your-key" \\\n  -e GEMINI_API_KEY="your-gemini-key" \\\n  -v $(pwd)/configs:/app/configs \\\n  khapu2906/coo-llm:latest\n'})}),"\n",(0,r.jsx)(n.h2,{id:"-documentation",children:"\ud83d\udcda Documentation"}),"\n",(0,r.jsx)(n.h3,{id:"quick-links",children:"Quick Links"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"docs/Intro/Overview.md",children:"Introduction"})}),": Overview and architecture"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"docs/Guides/Configuration.md",children:"Configuration"})}),": Complete configuration reference"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"docs/Reference/API.md",children:"API Reference"})}),": REST API documentation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"docs/Reference/Balancer.md",children:"Load Balancing"})}),": Load balancing algorithms and policies"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"docs/Guides/Deployment.md",children:"Deployment"})}),": Installation and production deployment"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"https://github.com/COO-LLM/coo-llm-main/tree/main/example/langchain-demo",children:"LangChain Demo"})}),": Integration examples"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"documentation-structure",children:"Documentation Structure"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Intro"}),": Overview, architecture, and getting started"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Guides"}),": User guides, configuration, and deployment"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Reference"}),": Technical API, configuration, and balancer reference"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Contributing"}),": Development guidelines and contribution process"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"\ufe0f-architecture",children:"\ud83c\udfd7\ufe0f Architecture"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Client Applications (OpenAI SDK, LangChain, etc.)\n    \u2193 HTTP/JSON (OpenAI-compatible API)\nCOO-LLM Proxy\n\u251c\u2500\u2500 \ud83c\udffa API Layer (OpenAI-compatible REST API)\n\u2502   \u251c\u2500\u2500 Chat Completions (/v1/chat/completions)\n\u2502   \u251c\u2500\u2500 Models (/v1/models)\n\u2502   \u2514\u2500\u2500 Admin API (/admin/v1/*)\n\u251c\u2500\u2500 \u2696\ufe0f Load Balancer (Intelligent Routing)\n\u2502   \u251c\u2500\u2500 Round Robin, Least Loaded, Hybrid algorithms\n\u2502   \u251c\u2500\u2500 Rate limiting & cost optimization\n\u2502   \u2514\u2500\u2500 Real-time performance tracking\n\u251c\u2500\u2500 \ud83d\udd0c Provider Adapters\n\u2502   \u251c\u2500\u2500 OpenAI (GPT-4, GPT-3.5)\n\u2502   \u251c\u2500\u2500 Google Gemini (1.5 Pro, etc.)\n\u2502   \u251c\u2500\u2500 Anthropic Claude (Opus, Sonnet)\n\u2502   \u2514\u2500\u2500 Custom providers\n\u251c\u2500\u2500 \ud83d\udcbe Storage Layer\n\u2502   \u251c\u2500\u2500 Redis (production, with clustering)\n\u2502   \u251c\u2500\u2500 Memory (development)\n\u2502   \u251c\u2500\u2500 File-based (simple deployments)\n\u2502   \u2514\u2500\u2500 HTTP (remote storage)\n\u2514\u2500\u2500 \ud83d\udcca Observability\n    \u251c\u2500\u2500 Structured logging (JSON)\n    \u251c\u2500\u2500 Prometheus metrics\n    \u251c\u2500\u2500 Response caching\n    \u2514\u2500\u2500 Health checks\n    \u2193\nExternal LLM Providers (OpenAI, Gemini, Claude APIs)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"-key-metrics",children:"\ud83d\udcca Key Metrics"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\ud83d\ude80 Load Balancing"}),": Intelligent distribution across 3+ providers"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\ud83d\udcb0 Cost Optimization"}),": Real-time cost tracking and automatic optimization"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u26a1 Rate Limiting"}),": Sliding window rate limiting with key rotation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\ud83d\udcc8 Performance"}),": Sub-millisecond routing with comprehensive monitoring"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\ud83d\udd12 Security"}),": API key masking and secure storage"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\ud83d\udcca Observability"}),": Prometheus metrics, structured JSON logging"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"COO-LLM"})," - The Intelligent LLM API Load Balancer \ud83d\ude80"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.em,{children:"Load balance your LLM API calls across multiple providers with OpenAI compatibility, real-time cost optimization, and enterprise-grade reliability."})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);